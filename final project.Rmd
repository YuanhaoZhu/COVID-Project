---
title: "final project"
author: "Yuanhao Zhu"
date: "4/18/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
##data processing

```{r}
#We use the raw data in sheet 2 for data processing. The transformed data is ill structured. For instance ln1 is 0 and missing values were also assigned value 0. 
library("readxl")
library("dplyr")
rawdata <- read_excel("COVID.xlsx", sheet = "Sheet2",col_names=T,range = cell_cols(1:9))
colnames(rawdata)<-c("CODE","COUNTRY",	"DATE",	"TC",	"TD","STI",	"POP","GDPCAP","HDI")
#a function take natrual log and leave 0 if the cell is 0 and NA if the cell is NA 
avoid_zero_ln<-function(x){
 n=ifelse(x == 0, 0, log(x))
 return(n)
}

data<-rawdata %>% mutate_at(c("TC",	"TD","STI",	"POP","GDPCAP"), avoid_zero_ln)
colnames(data)<-c("CODE","COUNTRY",	"DATE",	"logTC",	"logTD","logSTI",	"logPOP","logGDPCAP","HDI")
#keep both variables in log scale and original ones. 
#The processed data is  called covid. Note that NA values are perserved. 
covid<-cbind(data,rawdata[,c(4:8)])
head(covid)
```

>Data are in both natural log and original scale. 

| Variable Indicator   | Description  | Measurement |
| ------------- |:-------------:| :-----:|
| STI    | Stringency Index | COVID-19 PandemicLockdown |
|  TC    | Total Cases      |  COVID-19 PandemicTotal cases recorded  |
| TD | Total Death     | COVID-19 PandemicDeaths-   |
|  GDPCAP   | GDP Per Capital      |  Economic Growth  |
| HDI | Human Development Index      |  Poverty Alleviation |


```{r}
library("ggplot2")
theme_set(theme_bw())
library("sf")
library("rnaturalearth")
library("rnaturalearthdata")
library("maps")
world_map <- map_data("world")
```



```{r}
world_map <- map_data("world")
deathrate<-c()
for( i in unique(covid$COUNTRY)){
  d<-covid[covid$COUNTRY==i,11]
  p<-covid[covid$COUNTRY==i,13]
  if(all(is.na(p)) |all(is.na(d)) ){rate<-NA}
  else{
  totaldeath<-max(d,na.rm=T)
  population<-max(p,na.rm = T)
  rate<-(totaldeath/population)*100}
  deathrate<-c(deathrate,rate)
}
d_rate<-data.frame(region=unique(covid$COUNTRY), deathrate)
levels(d_rate$region)[levels(d_rate$region)=="United States"] <- "USA"
```

```{r}
comb <- left_join(world_map,d_rate, by = "region")
ggplot(comb, aes(long, lat, group = group))+
  geom_polygon(aes(fill = deathrate ), color = "white")+
  scale_fill_viridis_c(
  alpha = 0.7,
  begin = 0,
  end = 1,
  direction = -1,
  option = "A",
  values = NULL,
  space = "Lab",
  na.value = "grey80",
  guide = "colourbar",
  aesthetics = "fill"
)+labs(title="World Map of Total Death Rate for Each Country",
        x ="Longitude", y = "Latitude7")

```

```{r}
# plot trend of covid cases and death world wide
sub_covid<-covid[,c('DATE',"TC","TD")]

sub_covid$FDATE<-as.factor(sub_covid$DATE)
world_cases<-aggregate(TC~FDATE, data=sub_covid, FUN=sum ,na.action=na.omit)
world_death<-aggregate(TD~FDATE, data=sub_covid, FUN=sum ,na.action=na.omit)
world_death<-subset(world_death, select = -c(1) )
world_cd<-cbind(world_cases,world_death)
world_cd$logTC<-log(world_cd$TC)
world_cd$logTD<-log(world_cd$TD)
ggplot(data = world_cd, aes(x = as.Date(FDATE))) +
  geom_line(aes(y = logTC, colour = "logTC")) +
  geom_line(aes(y = logTD, colour = "logTD")) +
  scale_colour_manual("", values = c("logTC"="green", "logTD"="red")) +
  xlab("time") +
  ylab("log counts")+
  labs(title="total cases and deaths worldwide in log scale")


```
```{r}
#plot correlation between GDP VS STI AND 
deathrate<-c()
for( i in unique(covid$COUNTRY)){
  d<-covid[covid$COUNTRY==i,11]
  p<-covid[covid$COUNTRY==i,13]
  if(all(is.na(p)) |all(is.na(d)) ){rate<-NA}
  else{
  totaldeath<-max(d,na.rm=T)
  population<-max(p,na.rm = T)
  rate<-(totaldeath/population)*100}
  deathrate<-c(deathrate,rate)
}
```

```{r}
#correlation of total death vs HDI is different for underdeveloped developing and developed countries, result of the paper may be wrong! 
quantile(covid$GDPCAP,na.rm=T)
bygdp<-covid[,c('COUNTRY',"TD","GDPCAP","HDI")]
bygdp$type[bygdp$GDPCAP<5338.454]<-"UNDERDEVELOPED"
bygdp$type[bygdp$GDPCAP> 5338.454 &bygdp$GDPCAP<31400.840]<-"DEVELOPING"
bygdp$type[bygdp$GDPCAP>31400.840 ]<-"DEVELOPED"
ud<-bygdp[bygdp$type=="UNDERDEVELOPED",]
d<-bygdp[bygdp$type=="DEVELOPING",]
dd<-bygdp[bygdp$type=="DEVELOPED",]
ud_corr<-cor(ud$TD,ud$HDI,use="pairwise.complete.obs")
d_corr<-cor(d$TD,d$HDI,use="pairwise.complete.obs")
dd_corr<-cor(dd$TD,dd$HDI,use="pairwise.complete.obs")
ud_p<-cor.test(ud$TD,ud$HDI,use="pairwise.complete.obs")$p.value
d_p<-cor.test(d$TD,d$HDI,use="pairwise.complete.obs")$p.value
dd_p<-cor.test(dd$TD,dd$HDI,use="pairwise.complete.obs")$p.value
data.frame(type=c("underdeveloped","developing","developed"),corrs=c(ud_corr,d_corr,dd_corr),pval=c(ud_p,d_p,dd_p))
```
> In comparison to the paper, we find although in general total death has a positive correlation with HDI, the effect is insignificant for developing country, but is significant for underdeveloped, developed countries. Thus, we can think population control may not be a good idea for developing countries. Also for further regression analysis , we may need to create indicator variable for the degree of developement  for countries. 

##Regression part
```{r}
library(tidyverse)
```

```{r}
covid$DATE <- as.Date(covid$DATE , format = "%Y-%m-%d")
```

```{r}
#function to calculate mortality rate, return 0 if no case or if no death 
mrate<-function(td,tc){
  if (td==0){mortality<-0}
  else{mortality<-td/tc}
  return (mortality)
  
}
```


```{r}
library(tidyverse)
# Time Phase
begin_phase = as.Date("2020-02-01", format = "%Y-%m-%d")
dev_phase = as.Date("2020-05-01", format = "%Y-%m-%d")
outbreak_phase = as.Date("2020-07-01", format = "%Y-%m-%d")
regressiondata <- covid %>%  mutate(PHASE = case_when(
  DATE<=begin_phase ~ 0,
  DATE> begin_phase &DATE <=dev_phase ~ 1,
  DATE>=dev_phase ~ 2
))%>% filter(DATE==begin_phase |DATE==dev_phase|DATE==outbreak_phase)

# 0 = UNDERDEVELOPED, 1 = DEVELOPING, 2 = DEVELOPED
regressiondata$TYPE[regressiondata$GDPCAP<5338.454]<- 0
regressiondata$TYPE[regressiondata$GDPCAP>= 5338.454 & regressiondata$GDPCAP<31400.840]<- 1
covid$TYPE[covid$GDPCAP>=31400.840 ]<- 2
regressiondata<- regressiondata %>%
  drop_na()
regressiondata$mortality_rate<-as.vector(mapply(mrate,regressiondata$TD,regressiondata$TC))*100
regressiondata$PHASE<-as.factor(regressiondata$PHASE)
regressiondata$TYPE<-as.factor(regressiondata$TYPE)
regressiondata$GDP<- regressiondata$POP *regressiondata$GDPCAP
regressiondata$logGDP<- log(regressiondata$POP *regressiondata$GDPCAP)
head(regressiondata)
```

##Regression Analysis
```{r}
library("MASS")
#use robust regression method 
robust_regression_m1<-rlm(GDPCAP ~ TC+TD +logPOP+HDI+ STI:TYPE+STI:PHASE, data = regressiondata)
summary(robust_regression_m1)
regression_m1<-lm(GDPCAP ~ TC+TD +logPOP+HDI+ STI:TYPE+STI:PHASE, data = regressiondata)
summary(regression_m1)
```

```{r}
stepAIC(regression_m1,direction="both")
```

```{r}
regression_m1_final<-lm(GDPCAP ~ TC+TD +logPOP+HDI+ STI:TYPE, data = regressiondata)
summary(regression_m1_final)
```


> Based on our first regression model, we want to investigate the association between STI and GDP per capita. We created three addtional varaible, one is type, which indicates whether a country is developed/ developing or underdeveloped based on gdp per capita. The other variable is phase, which divide the covid period into three main phases: 0 is initial phase, 1 is developing phase, 2 is total outbreak phase. . We created these additional variables in order to study the relationship between STI and GDP per capita in different types of countries and different phases of covid 19. 
> Our first model regresses GDP per capita against total death, total case, log population, HDI and interaction between STI and type of country and interaction between STI and phase of covid. Thus the formula of our model is : 

GDPCAP = $\beta_1 *TC +\beta_2*TD+\beta_3*logPOP +\beta_4*HDI+ \beta_5*STI*developed+\beta_6*STI*developing +\beta_7*STI*underdeveloped +\beta_8*STI*PHASE1+\beta_9*STI*PHASE2$

> We further used stepwise AIC method for variable selection and found that the STI:PHASE interaction term cannot add siginificant additional information to our model. Thus, we deleted them. Thus, the relationship between STI and GPD per capita is same for all phases of covid19. 

> From the above result, we saw that the inference of covariates of both robust and ordinary least square method are consistent. We saw that there is a positive association between total case and GDPCAP, indicating that economic growth and total case number have a positive association. It makes sense that, the more active and developed the economy, the more easier for the virus to transmit among people due to human-human interactions. total death is negatively associated with GDP per capita. Thus, we can interpret it as the more developed the economy is, the better medical care the country can provide, thus reducing the total death. Population is negatively associated with GDP per capita. Therefore, too much population can negatively impact the economic growth. The stringency index is positively associated with gdp per capital for developed countries and have negative association for  developing and underdeveloped countries. Given it is a developed country, the higher the STI, the higher the GDP per capita. given it is a underdeveloped/ developing country, the higher the STI, the lower the GDP per capita. Thus, for the developed countries,the active economy requires the government to apply much stricter covid policy to prevent further transmission. And for developing and underdeveloped countries, those with higher GDP per capita and more active economy tend to apply less strict policy. This may due to the government chooses not to address COVID issue or the unwillingness to sacrifice the economy. 
 


> you can start with the second model to investigate the relationship amongst hdi,total death  and types of country 

```{r}
head(regressiondata)
m2<-lm(HDI~ TC + STI+ GDPCAP+ TD:TYPE,data=regressiondata)
summary(m2)
```

```{r}
stepAIC(m2,direction="both")
```

## HDI and GDP Distribution 

```{r}
library(reshape)
scaleFUN <- function(x) sprintf("%.5f", x)
rev <- regressiondata$HDI
ggplot(data = melt(rev), aes(x = value)) +
    stat_density() + 
    ggtitle("Plot of HDI Distribution") +
    theme(plot.title = element_text(hjust = 0.5)) + 
    scale_x_continuous(labels=scales::dollar_format()) +
    scale_y_continuous(labels=scaleFUN) +
    geom_vline(xintercept = mean(rev), linetype="dotted", 
                color = "red", size=1.5) 

```

```{r}
library(reshape)
scaleFUN <- function(x) sprintf("%.5f", x)
rev <- regressiondata$GDPCAP
ggplot(data = melt(rev), aes(x = value)) +
    stat_density() + 
    ggtitle("Plot of GDPCAP Distribution") +
    theme(plot.title = element_text(hjust = 0.5)) + 
    scale_x_continuous(labels=scales::dollar_format()) +
    scale_y_continuous(labels=scaleFUN) +
    geom_vline(xintercept = mean(rev), linetype="dotted", 
                color = "red", size=1.5) 
```

> As seen above, HDI and GDP does not follow a normal distribution, thus it is not appropriate to assume linearity. Also, given the ranges of both outputs are $0 to infinity, we hypothesis that these models follow more closely to a Poisson Distribution. Before doing so, lets plot the linear models results to verify our linearity assumptions. 

```{r}
par(mfrow=c(2,2))
plot(m2)
```


## Poisson Regressions Analysis

```{r}
```


```{r}
regressiondata$HDI = as.integer(regressiondata$HDI)
regressiondata$GDPCAP = as.integer(regressiondata$GDPCAP)


gdp.glm <- glm(GDPCAP ~ TC + STI+ TD + mortality_rate + TYPE + PHASE, family="poisson", data=regressiondata)
summary(gdp.glm)

mu <- mean(regressiondata$GDPCAP)
plot(log(fitted(gdp.glm)),log((regressiondata$GDPCAP-fitted(gdp.glm))^2),xlab=expression(hat(mu)),ylab=expression((y-hat(mu))^2),pch=20,col="blue")
abline(0,1) 
dp = sum(residuals(gdp.glm,type ="pearson")^2)/gdp.glm$df.residual
print(dp)
```



> From above, we see in our GDPCAP Poisson Regression model that the residual deviance is not a 1:1 ratio with the degrees of freedom. Thus, meaning that there is overdispersion in our data. THis is verified by plotting the variance against the mean. In the plot, we can see that a large amount of our data has variance above the mean, which leads us to assume that a negative binomial model will provide a better fit. 

```{r}
library(MASS)
regressiondata$GDPCAP = as.integer(regressiondata$GDPCAP)
rev.glm <- glm.nb(GDPCAP ~TC + STI+ TD + HDI + mortality_rate + TYPE + PHASE,data=regressiondata , maxit = 100)
summary(rev.glm)
plot(rev.glm)
```

> From our Negative Binomial model, we can see that the residual variance is very close to a 1:1 ratio with our degrees of freedom and this verifies the accuracy. With that said, we believe the results from the original paper to be questionable. To start, let's look at the effects of COVID, including total deaths and total cases. They are both statistically signifigant for the GDPCAP, but interestingly enough, the total number of cases are positively correlated with GDPCAP, while the total number of deaths are negatively correlated. We believe this is the case because there is a low morality rate from COVID, but when someone does die from COVID, it drastically effects the economy. Additionally, the morality rate per capita is not statistically significant. Rather, given the fact if the country is developing or is developed is more important. 


> HELP HERE: why does the Poisson regressions not work for HDI?

```{r}
hdi.glm <- glm(HDI ~TC + STI+ TD + GDPCAP , family="poisson", data=regressiondata)
summary(hdi.glm)

mu <- mean(regressiondata$HDI)
plot(log(fitted(hdi.glm)),log((regressiondata$HDI-fitted(hdi.glm))^2),xlab=expression(hat(mu)),ylab=expression((y-hat(mu))^2),pch=20,col="blue")
abline(0,1) 
dp = sum(residuals(hdi.glm,type ="pearson")^2)/hdi.glm$df.residual
```


## Decision Tree
```{r}
set.seed(4740)
trainid = sample(nrow(regressiondata), nrow(regressiondata)*0.7, replace = FALSE)
trainingdata = regressiondata[trainid,]
testdata = regressiondata[-trainid,]
library(caret)
library(rpart)
library(e1071)
library(rpart.plot)
numFold = trainControl(method="cv", number = 10)
cpGrid = expand.grid(.cp = seq(0.01, 0.5, 0.01))
train(TYPE~ HDI + TC + TD +STI +POP  + PHASE +
                          mortality_rate , data=trainingdata, method = "rpart", trControl =numFold, tuneGrid = cpGrid)
treeCV = rpart(TYPE ~ HDI + TC + TD +STI +POP  + PHASE +
                          mortality_rate, data=trainingdata, method="class", cp=0.05)
predictCV = predict(treeCV, newdata=testdata, type="class")
length(predictCV)
length(testdata$TYPE)
t = table(testdata$TYPE, predictCV)
rpart.plot(treeCV)
confusionMatrix(t)
```

## Random Forest Part 1
```{r}
library(stringr) 
library("openxlsx")
library(data.table)
library(corrplot)
library(ggpubr)
library(ggplot2)
library(Matrix)
library(lme4)
library(lmerTest)
library(factoextra)
library(cluster)
library(epiR)
library("gplots")
library(randomForest)
library(pROC)
```

```{r}
# Train/test split
trainid = sample(nrow(regressiondata), nrow(regressiondata)*0.7, replace = FALSE)
trainingdata = regressiondata[trainid,]
testdata = regressiondata[-trainid,]
n<-16
# Find best Mtree
m_tree <- c()
for(i in 1:(n-1)){
  mtry_fit<-randomForest(TYPE ~ logTC + logTD + logSTI + logPOP + logGDPCAP + HDI + TC + TD +STI +POP + GDPCAP + PHASE +
                          mortality_rate + GDP + logGDP, data=trainingdata, mtry=i)
  err<-mean(mtry_fit$err.rate)
  print(err)
  m_tree<- c(m_tree, err)
}
m_tree
min(m_tree)
```
> The best mtree is with 6, and gives an error of 7.065e-05


```{r}
ntree_fit<-randomForest(TYPE ~ logTC + logTD + logSTI + logPOP  + HDI + TC + TD +STI +POP  + PHASE +
                          mortality_rate , data = trainingdata, mtry = 6, ntree = 100, importance = TRUE)
plot(ntree_fit)
legend("top", colnames(ntree_fit$err.rate),col=1:4,cex=0.8,fill=1:4)

rf = randomForest(TYPE ~ logTC + logTD + logSTI + logPOP  + HDI + TC + TD +STI +POP  + PHASE +
                          mortality_rate, data = trainingdata, mtry = 6, ntree = 20,importance = TRUE, proxmity = TRUE)
rf

# MDSplot(rf, trainingdata$TYPE)

importance<-importance(rf)
importance


varImpPlot(rf, main = "variable importance")

pred1<-predict(rf, data=trainingdata)
Freq1<-table(pred1, trainingdata$TYPE)
sum(diag(Freq1))/sum(Freq1)

plot(margin(rf,trainingdata$TYPE))


pre <- predict(rf,newdata=testdata)

obs_p_ran = data.frame(prob=pre,obs=testdata$TYPE)

table(testdata$TYPE,pre,dnn=c("real","predict"))

ran_roc <- roc(testdata$TYPE,as.numeric(pre))
plot(ran_roc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main='RandomForest ROC,mtry=4,ntree=20')
#MDSplot(rf,fac=data_train$Level)
par(mfrow=c(1,2))

varImpPlot(rf, main = "variable importance")
plot(ran_roc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE,main='RandomForest ROC,mtry=4,ntree=20')
```





